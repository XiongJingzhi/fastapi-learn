# 07b. APScheduler é«˜çº§ç‰¹æ€§

## ğŸ¯ å­¦ä¹ ç›®æ ‡

æŒæ¡APSchedulerçš„ç”Ÿäº§çº§ç”¨æ³•ï¼ŒåŒ…æ‹¬ä»»åŠ¡æŒä¹…åŒ–ã€é”™è¯¯å¤„ç†ã€ä»»åŠ¡ç®¡ç†ã€‚

---

## ğŸ“‚ å®é™…åœºæ™¯

### åœºæ™¯ 1ï¼šæ•°æ®æ¸…ç†

**é—®é¢˜**ï¼šæ•°æ®åº“ä¸­æœ‰å¾ˆå¤šè¿‡æœŸtokenï¼Œéœ€è¦å®šæœŸæ¸…ç†

**è§£å†³æ–¹æ¡ˆ**ï¼šå®šæ—¶æ¸…ç†ä»»åŠ¡

```python
import asyncio
from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

async def cleanup_expired_tokens():
    """æ¸…ç†è¿‡æœŸtoken"""
    # 1. æŸ¥è¯¢è¿‡æœŸtoken
    expired_tokens = await get_expired_tokens()
    print(f"Found {len(expired_tokens)} expired tokens")

    # 2. åˆ é™¤
    for token in expired_tokens:
        await delete_token(token)

    print(f"Deleted {len(expired_tokens)} tokens")

# æ¯å°æ—¶æ‰§è¡Œ
scheduler.add_job(
    cleanup_expired_tokens,
    'interval',
    hours=1,
    id='cleanup_tokens'
)
```

**è´¹æ›¼æŠ€å·§**ï¼š
- å°±åƒæ¯å¤©å®šæ—¶æ¸…ç†åƒåœ¾
- ä¸æ¸…ç†ä¼šå ç”¨ç©ºé—´ï¼ˆè¿‡æœŸtokenå ç”¨æ•°æ®åº“ç©ºé—´ï¼‰

---

### åœºæ™¯ 2ï¼šç¼“å­˜é¢„çƒ­

**é—®é¢˜**ï¼šç¼“å­˜è¿‡æœŸåï¼Œç¬¬ä¸€ä¸ªç”¨æˆ·è®¿é—®ä¼šå¾ˆæ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼šæå‰åŠ è½½çƒ­ç‚¹æ•°æ®

```python
async def cache_warmup():
    """ç¼“å­˜é¢„çƒ­"""
    # åŠ è½½çƒ­ç‚¹æ•°æ®åˆ°ç¼“å­˜
    hot_data = await get_hot_data()
    for data in hot_data:
        await cache.set(f"data:{data.id}", data)

    print("Cache warmed up")

# æ¯å°æ—¶é¢„çƒ­
scheduler.add_job(
    cache_warmup,
    'interval',
    hours=1,
    id='cache_warmup'
)
```

**è´¹æ›¼æŠ€å·§**ï¼š
- å°±åƒæå‰é¢„çƒ­çƒ¤ç®±
- é¢„çƒ­åä½¿ç”¨æ›´å¿«ï¼ˆç¼“å­˜å‘½ä¸­æ›´å¿«ï¼‰

---

## ğŸ’¾ ä»»åŠ¡æŒä¹…åŒ–

### ä¸ºä»€ä¹ˆéœ€è¦æŒä¹…åŒ–ï¼Ÿ

**é—®é¢˜**ï¼šç¨‹åºé‡å¯åï¼Œä»»åŠ¡ä¸¢å¤±

```
æ²¡æœ‰æŒä¹…åŒ–ï¼š
    æ·»åŠ ä»»åŠ¡ â†’ ç¨‹åºé‡å¯ â†’ ä»»åŠ¡ä¸¢å¤± âŒ

æœ‰æŒä¹…åŒ–ï¼š
    æ·»åŠ ä»»åŠ¡ â†’ ä¿å­˜åˆ°æ•°æ®åº“ â†’ ç¨‹åºé‡å¯ â†’ ä»æ•°æ®åº“æ¢å¤ âœ…
```

---

### ä½¿ç”¨SQLAlchemyJobStore

```python
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore

# é…ç½®JobStore
jobstores = {
    'default': SQLAlchemyJobStore(url='sqlite:///jobs.db')
}

# åˆ›å»ºè°ƒåº¦å™¨
scheduler = AsyncIOScheduler(jobstores=jobstores)

# æ·»åŠ ä»»åŠ¡
scheduler.add_job(my_task, 'interval', minutes=5)

# å¯åŠ¨
scheduler.start()

# ä»»åŠ¡ä¼šä¿å­˜åˆ°jobs.dbæ–‡ä»¶
```

**è´¹æ›¼æŠ€å·§**ï¼š
- JobStore = ä»»åŠ¡è®°äº‹æœ¬
- è®°ä¸‹æ¥å°±ä¸æ€•å¿˜è®°

---

## ğŸ”§ ä»»åŠ¡ç®¡ç†

### æŸ¥è¯¢ä»»åŠ¡

```python
# è·å–æ‰€æœ‰ä»»åŠ¡
jobs = scheduler.get_jobs()
for job in jobs:
    print(f"Job ID: {job.id}, Next run: {job.next_run_time}")

# è·å–ç‰¹å®šä»»åŠ¡
job = scheduler.get_job('my_job_id')
print(f"Job: {job.name}")
```

---

### æš‚åœ/æ¢å¤ä»»åŠ¡

```python
# æš‚åœä»»åŠ¡
scheduler.pause_job('my_job_id')

# æ¢å¤ä»»åŠ¡
scheduler.resume_job('my_job_id')

# ä¿®æ”¹ä»»åŠ¡
scheduler.modify_job('my_job_id', minutes=10)
```

---

### åˆ é™¤ä»»åŠ¡

```python
# åˆ é™¤ç‰¹å®šä»»åŠ¡
scheduler.remove_job('my_job_id')

# åˆ é™¤æ‰€æœ‰ä»»åŠ¡
scheduler.remove_all_jobs()
```

---

## âš ï¸ é”™è¯¯å¤„ç†

### ä»»åŠ¡å¤±è´¥å¤„ç†

```python
import logging

logger = logging.getLogger(__name__)

async def risky_task():
    """å¯èƒ½å¤±è´¥çš„ä»»åŠ¡"""
    try:
        # å¯èƒ½å¤±è´¥çš„æ“ä½œ
        await do_something_risky()
        logger.info("Task succeeded")
    except Exception as e:
        logger.error(f"Task failed: {e}")
        # å†³å®šæ˜¯å¦é‡æ–°æŠ›å‡ºå¼‚å¸¸
        raise

scheduler.add_job(
    risky_task,
    'interval',
    minutes=5,
    max_instances=1,  # é˜²æ­¢ä»»åŠ¡é‡å 
    misfire_grace_time=60  # å®¹å¿1ç§’å»¶è¿Ÿ
)
```

---

### ä»»åŠ¡é‡å é—®é¢˜

**é—®é¢˜**ï¼šä¸Šæ¬¡ä»»åŠ¡è¿˜æ²¡æ‰§è¡Œå®Œï¼Œä¸‹æ¬¡å°±å¼€å§‹äº†

**è§£å†³æ–¹æ¡ˆ**ï¼šè®¾ç½®`max_instances=1`

```python
scheduler.add_job(
    slow_task,
    'interval',
    minutes=5,
    max_instances=1  # åŒæ—¶åªå…è®¸1ä¸ªå®ä¾‹
)
```

**è´¹æ›¼æŠ€å·§**ï¼š
- å°±åƒç”µæ¢¯ï¼ˆåŒæ—¶åªèƒ½åœ¨ä¸€ä¸ªæ¥¼å±‚ï¼‰
- é˜²æ­¢é‡å¤æ‰§è¡Œå¯¼è‡´é—®é¢˜

---

### ä»»åŠ¡é”™è¿‡æ‰§è¡Œ

**é—®é¢˜**ï¼šç³»ç»Ÿæš‚åœï¼Œä»»åŠ¡é”™è¿‡äº†æ‰§è¡Œæ—¶é—´

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨`coalesce`å’Œ`misfire_grace_time`

```python
scheduler.add_job(
    my_task,
    'interval',
    minutes=5,
    coalesce=True,  # é”™è¿‡çš„ä»»åŠ¡åˆå¹¶æ‰§è¡Œ
    misfire_grace_time=60  # å®¹å¿60ç§’å»¶è¿Ÿ
)
```

---

## ğŸ¯ å®Œæ•´ç¤ºä¾‹ï¼šæ•°æ®æ¸…ç†æœåŠ¡

```python
import asyncio
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataCleanupService:
    """æ•°æ®æ¸…ç†æœåŠ¡"""

    def __init__(self):
        # é…ç½®æŒä¹…åŒ–
        jobstores = {
            'default': SQLAlchemyJobStore(url='sqlite:///cleanup.db')
        }

        self.scheduler = AsyncIOScheduler(jobstores=jobstores)

    async def cleanup_expired_tokens(self):
        """æ¸…ç†è¿‡æœŸtoken"""
        try:
            logger.info("Starting token cleanup...")

            # æ¨¡æ‹Ÿæ•°æ®åº“æ“ä½œ
            expired = await self._get_expired_tokens()
            logger.info(f"Found {len(expired)} expired tokens")

            deleted = await self._delete_tokens(expired)
            logger.info(f"Deleted {deleted} tokens")

        except Exception as e:
            logger.error(f"Cleanup failed: {e}")
            raise

    async def _get_expired_tokens(self):
        await asyncio.sleep(0.1)
        return list(range(10))

    async def _delete_tokens(self, tokens):
        await asyncio.sleep(0.2)
        return len(tokens)

    def start(self):
        # æ¯å°æ—¶æ¸…ç†
        self.scheduler.add_job(
            self.cleanup_expired_tokens,
            'interval',
            hours=1,
            id='cleanup_tokens',
            max_instances=1,
            misfire_grace_time=300
        )

        self.scheduler.start()
        logger.info("Data cleanup service started")

# è¿è¡Œ
if __name__ == "__main__":
    service = DataCleanupService()
    service.start()

    try:
        asyncio.Event().wait()
    except KeyboardInterrupt:
        logger.info("Shutting down...")
        service.scheduler.shutdown()
```

---

## ğŸ¯ å°å®éªŒ

### å®éªŒ 1ï¼šæŒä¹…åŒ–ä»»åŠ¡

```python
from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore

jobstores = {
    'default': SQLAlchemyJobStore(url='sqlite:///test.db')
}

scheduler = BlockingScheduler(jobstores=jobstores)

def job():
    print("Job executed")

scheduler.add_job(job, 'interval', seconds=10, id='test_job')

scheduler.start()
```

**æµ‹è¯•**ï¼šé‡å¯ç¨‹åºï¼Œä»»åŠ¡ä»ç„¶å­˜åœ¨

---

### å®éªŒ 2ï¼šä»»åŠ¡ç®¡ç†

```python
from apscheduler.schedulers.blocking import BlockingScheduler

scheduler = BlockingScheduler()

def job():
    print("Job running")

job = scheduler.add_job(job, 'interval', seconds=5)

# 5ç§’åæš‚åœ
import time
time.sleep(5)
scheduler.pause_job(job.id)

# 5ç§’åæ¢å¤
time.sleep(5)
scheduler.resume_job(job.id)

scheduler.start()
```

---

## ğŸ“š æ£€æŸ¥ç†è§£

1. **ä¸ºä»€ä¹ˆéœ€è¦ä»»åŠ¡æŒä¹…åŒ–ï¼Ÿ**
   - æç¤ºï¼šç¨‹åºé‡å¯

2. **`max_instances`çš„ä½œç”¨ï¼Ÿ**
   - æç¤ºï¼šé˜²æ­¢ä»»åŠ¡é‡å 

3. **`coalesce`çš„ä½œç”¨ï¼Ÿ**
   - æç¤ºï¼šåˆå¹¶é”™è¿‡çš„ä»»åŠ¡

---

## ğŸš€ ä¸‹ä¸€æ­¥

- å­¦ä¹ Celery Beat â†’ `notes/07c_celery_beat_intro.md`
- æŸ¥çœ‹å®Œæ•´ç¤ºä¾‹ â†’ `examples/07_scheduled_tasks/level2_data_cleanup.py`

---

**è®°ä½ï¼šæŒä¹…åŒ–è®©ä½ çš„ä»»åŠ¡ä¸ä¸¢å¤±ï¼** ğŸš€
